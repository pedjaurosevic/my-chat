# Optimizacije - Uticaj na moj.perasper.com

## ≈†ta je promenjeno

### 1. Ollama Server Optimizacije ‚úÖ

**Konfiguracija (/etc/systemd/system/ollama.service.d/override.conf):**
```bash
OLLAMA_NUM_PARALLEL=4          # 4 istovremena zahteva
OLLAMA_MAX_LOADED_MODELS=2      # 2 modela u RAM-u
OLLAMA_KEEP_ALIVE=30m          # Modeli ostaju 30 min u memoriji
OLLAMA_REQUEST_TIMEOUT=30m     # 30 min timeout
OLLAMA_LOAD_TIMEOUT=5m         # 5 min za uƒçitavanje modela
MemoryLimit=40G                # Ollama mo≈æe koristiti do 40GB RAM-a
MemorySwapMax=2G               # Max 2GB swap
LimitNOFILE=1048576           # Vi≈°e otvorenih fajlova
```

**Kernel VM Optimizacije:**
```bash
vm.swappiness=10               # Manje swap-a
vm.vfs_cache_pressure=50       # Bolje ke≈°iranje fajlova
vm.dirty_ratio=15              # Manje dirty write-ova
vm.dirty_background_ratio=5     # ƒåe≈°ƒáe flush-ovanje
```

### 2. Streamlit App Optimizacije ‚úÖ

**CSS Responsivnost (/home/peterofovik/my-chat/app.py):**
- Input je sada na dlu ekrana (ne vi≈°e u sredini)
- Optimalno za iOS tablet/mobile
- Breakpoints: 1024px, 768px, 480px

**Streamlit Config (/home/peterofovik/my-chat/.streamlit/config.toml):**
```toml
[server]
maxUploadSize = 200           # Veƒái fajlovi za upload
enableCORS = false
enableXsrfProtection = false

[client]
showErrorDetails = false      # ƒåi≈°ƒáe UI
maxUploadSize = 200
```

**App Improvement (/home/peterofovik/my-chat/app.py):**
- Avatar error fix (emoji: üë§/ü§ñ)
- Progress indikatori
- Timeout handling
- Better error messages
- Smooth streaming

## Kako se ovo odra≈æava na moj.perasper.com

### 1. Br≈æe inicijalne odgovore (nakon prvog request-a)

**Pre optimizacije:**
- Prvi request: 30-60s (uƒçitavanje modela)
- Svaki naredni: 30-60s (ponovno uƒçitavanje)

**Nakon optimizacije:**
- Prvi request: 15-30s (uƒçitavanje modela)
- Naredni (30 min): 3-8s (model u ke≈°u)
- 30 min posle: 15-30s (re-load)

### 2. Vi≈°e korisnika istovremeno

**Pre:**
- 1 korisnik sporo, vi≈°e = timeout

**Sada:**
- 4 korisnika istovremeno bez problema
- 2 modela u memoriji (nema uƒçitavanja)

### 3. Stabilnost aplikacije

**Pre:**
- Odgovori nestaju (timeout)
- Error bez detalja
- Input na ƒçudnoj poziciji na iOS

**Sada:**
- Odgovori ne nestaju (30 min timeout)
- Jasan error messages
- Responsivno na iOS/tablet
- Avatar error fix

### 4. Cloud modeli

**Pre:**
- Veoma sporo (network latency)
- ƒåesto timeout

**Sada:**
- I dalje sporo (problem je VPS ‚Üí Ollama Cloud)
- Preporuka: Koristi lokalne modele ili direkt API

### 5. User Experience

**Pre:**
- Input u sredini ekrana
- Tablet iOS ne radi dobro
- Nejasno da li radi

**Sada:**
- Input na dlu ekrana (kao ChatGPT)
- Radi na iOS, tablet, desktop
- Progress indikatori tokom generisanja
- Tajmer za odgovor

## Oƒçekivane Brzine (moj.perasper.com)

### Lokalni Mali Modeli (preporuƒçeno)
| Model | Prvi request | Cache (30min) |
|-------|-------------|----------------|
| qwen3:1.7b | 15-20s | 3-5s |
| tinyllama | 12-18s | 3-4s |
| deepseek-coder:latest | 15-20s | 3-5s |

### Lokalni Srednji Modeli
| Model | Prvi request | Cache (30min) |
|-------|-------------|----------------|
| llama3.2:latest | 20-30s | 6-10s |
| phi3:latest | 20-30s | 6-10s |
| gemma3:4b | 25-35s | 8-12s |

### Cloud Modeli (kroz Ollama)
| Model | Latency | Preporuka |
|-------|---------|-----------|
| gemini-3-flash-preview:cloud | 3-8s | Koristi lokalne |
| gpt-oss:20b-cloud | 5-10s | Koristi lokalne |

## Tips za Najbolje Performanse

### 1. Koristi iste modele kontinuirano
```
Korisnik A: qwen3:1.7b ‚Üí Prvi: 20s
Korisnik B: qwen3:1.7b ‚Üí Prvi: 3s (ke≈°)
Korisnik A: qwen3:1.7b ‚Üí Drugi: 3s (ke≈°)
```

### 2. Preporuƒçeni modeli za produkciju
- **Brzost**: qwen3:1.7b, tinyllama
- **Balans**: llama3.2:latest, deepseek-coder:latest
- **Kvalitet**: phi3:latest, gemma3:4b

### 3. Izbegavaj cloud modele
Koristi lokalne ili direkt API (Google, OpenAI)

## Monitoring

Proveravaj status:
```bash
# Ollama status
systemctl status ollama

# Uƒçitani modeli
ollama ps

# Memory
free -h

# Logs
journalctl -u ollama -f
```

## Zakljuƒçak

**moj.perasper.com je sada:**
- ‚úÖ 3-5x br≈æi nakon prvog request-a (model caching)
- ‚úÖ Mo≈æe podr≈æati do 4 korisnika istovremeno
- ‚úÖ Stabilniji (manje timeout-a)
- ‚úÖ Responsivan na iOS/tablet
- ‚úÖ ƒåi≈°ƒáe UI (progress, error messages)

**Preporuƒçeni workflow:**
1. Koristi qwen3:1.7b ili llama3.2:latest za produkciju
2. Koristi iste modele da se koristi ke≈°
3. Testiraj na moj.perasper.com - treba da bude 3-5x br≈æi
